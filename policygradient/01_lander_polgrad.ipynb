{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d53fa1-7364-404b-a383-dd6f5c9c48db",
   "metadata": {
    "id": "35d53fa1-7364-404b-a383-dd6f5c9c48db"
   },
   "source": [
    "[Hands on RL Policy Gradient](https://github.com/PacktPublishing/Hands-on-Reinforcement-Learning-with-PyTorch/blob/master/Section%204/4.3%20Policy%20Gradients%20REINFORCE.ipynb)<br>\n",
    "[Policy Gradient Math](https://towardsdatascience.com/policy-gradients-in-reinforcement-learning-explained-ecec7df94245)<br>\n",
    "[Vanilla Policy Gradient](https://spinningup.openai.com/en/latest/algorithms/vpg.html)<br>\n",
    "[RL by Phil Tabor](https://github.com/philtabor/Youtube-Code-Repository/tree/master/ReinforcementLearning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "PxLtlMhE0uD0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87763,
     "status": "ok",
     "timestamp": 1710145757303,
     "user": {
      "displayName": "Arindam Dey",
      "userId": "10651625546197419632"
     },
     "user_tz": -330
    },
    "id": "PxLtlMhE0uD0",
    "outputId": "4d8ae9cc-d9bf-4c0e-ea7c-9cf921befc20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install swig\n",
    "#!pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168d04e4-18b5-4a32-ac2c-d787c36bf205",
   "metadata": {
    "id": "168d04e4-18b5-4a32-ac2c-d787c36bf205"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import cuda, device, distributions\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torch.distributions import Categorical\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import gymnasium as gym\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ce09f3-e160-43b3-949a-736f79a10e62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1710145767040,
     "user": {
      "displayName": "Arindam Dey",
      "userId": "10651625546197419632"
     },
     "user_tz": -330
    },
    "id": "f3ce09f3-e160-43b3-949a-736f79a10e62",
    "outputId": "cb67287f-5108-4d7e-fa2f-a6039eada8e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____OBSERVATION SPACE_____ \n",
      "\n",
      "The State Space is:  8\n",
      "Sample observation [ 0.9462635  -0.229104    2.8404567  -4.154978    2.1169014   0.6737268\n",
      "  0.83467776  0.4847395 ]\n"
     ]
    }
   ],
   "source": [
    "env_id = \"LunarLander-v2\"\n",
    "env = gym.make(env_id)#,render_mode=\"human\")\n",
    "\n",
    "s_size = env.observation_space.shape[0]\n",
    "a_size = env.action_space.n\n",
    "\n",
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"The State Space is: \", s_size)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92dc078a-f91b-40e3-9da3-97fb63177f3d",
   "metadata": {
    "id": "92dc078a-f91b-40e3-9da3-97fb63177f3d"
   },
   "outputs": [],
   "source": [
    "device = device(\"cuda:0\" if cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877dfcb2-324c-402d-a75f-55a9decc8d5f",
   "metadata": {
    "id": "877dfcb2-324c-402d-a75f-55a9decc8d5f"
   },
   "outputs": [],
   "source": [
    "def calc_disc_return(r_t , gamma = 0.998):\n",
    "\n",
    "    G_t = deque(maxlen = len(r_t))\n",
    "    G_t.append(r_t[-1])\n",
    "\n",
    "    for i in reversed(r_t[:-1]):\n",
    "        disc = i + (gamma*G_t[0])\n",
    "        G_t.appendleft(disc)\n",
    "\n",
    "    return np.array(G_t)\n",
    "\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.dense_layer_1 = nn.Linear(state_size, hidden_size)\n",
    "        self.dense_layer_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(x,-1.1,1.1)\n",
    "        x = F.relu(self.dense_layer_1(x))\n",
    "        x = F.relu(self.dense_layer_2(x))\n",
    "        return F.softmax(self.output(x),dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96aabf3a-08fe-499f-aee8-b7699b50a619",
   "metadata": {
    "id": "96aabf3a-08fe-499f-aee8-b7699b50a619"
   },
   "outputs": [],
   "source": [
    "hidden_layer = 64\n",
    "gamma = 0.99\n",
    "learning_rate = 0.001\n",
    "episodes = 100_000\n",
    "avg_win_size = 50\n",
    "epi_results = deque(maxlen=avg_win_size)\n",
    "\n",
    "policy_net = PolicyNet(s_size, a_size, hidden_layer).to(device)\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "984124ae-14a5-4747-b375-f26f2bf39230",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = os.path.join('.','artefacts',f'{env_id}_policygradient.csv')\n",
    "log_file = open(log_file_name, \"w\")\n",
    "log_file.write(f'episode,loss,rewards,l2_grad,max_grad\\n')\n",
    "\n",
    "model_file = os.path.join('.','models',f'{env_id}_policygradient.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342d254-377e-4208-b4c3-235e6df12dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fcac59a-0b87-4ed7-9df2-3b4875cb062c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3403475,
     "status": "ok",
     "timestamp": 1710149180584,
     "user": {
      "displayName": "Arindam Dey",
      "userId": "10651625546197419632"
     },
     "user_tz": -330
    },
    "id": "3fcac59a-0b87-4ed7-9df2-3b4875cb062c",
    "outputId": "d9c7e475-4cb6-4d31-82b9-34a57f8f0b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epi:06200 reward:   92.42 loss:    4.02 mean_rewards:  167.83\n",
      "epi:06210 reward:  253.87 loss:   32.09 mean_rewards:  181.06\n",
      "epi:06220 reward:  210.94 loss:   11.78 mean_rewards:  195.84\n"
     ]
    }
   ],
   "source": [
    "for epi in range(episodes):\n",
    "\n",
    "    s = env.reset()[0]\n",
    "    term , trunc = False, False\n",
    "    rewards, states , actions = [], [], []\n",
    "    win = 0\n",
    "\n",
    "    while not any([term, trunc]):\n",
    "\n",
    "        states.append(s)\n",
    "        obs = torch.FloatTensor(np.expand_dims(s,0)).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p_vals = policy_net(obs)\n",
    "            p_vals = torch.squeeze(p_vals)\n",
    "\n",
    "        p_vals = p_vals.detach().cpu().numpy()\n",
    "        a = np.random.choice(a_size, p=p_vals)\n",
    "\n",
    "        s_, r, term ,trunc, _  = env.step(a)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        s=np.copy(s_)\n",
    "\n",
    "    state_t = torch.FloatTensor(states).to(device)\n",
    "    action_t = torch.LongTensor(actions).to(device).view(-1,1)\n",
    "    return_t = torch.FloatTensor(calc_disc_return(rewards, gamma)).to(device).view(-1,1)\n",
    "    epi_results.append(np.sum(rewards))\n",
    "\n",
    "    selected_action_prob = policy_net(state_t).gather(1, action_t)\n",
    "    loss = torch.mean(-torch.log(selected_action_prob) * return_t)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    grads = np.concatenate([p.grad.data.detach().cpu().numpy().flatten()\n",
    "    for p in policy_net.parameters()\n",
    "    if p.grad is not None])\n",
    "    \n",
    "    grad_l2 = np.sqrt(np.mean(np.square(grads)))\n",
    "    grad_max = np.max(np.abs(grads))\n",
    "    \n",
    "    \n",
    "    log_file.write(f'{epi},{loss.item():.2f},{np.sum(rewards):.2f},{grad_l2:.4f},{grad_max:.4f}\\n')\n",
    "\n",
    "    if epi%100==0:\n",
    "        clear_output()\n",
    "    if epi%10==0:\n",
    "        print(f'epi:{epi:05d} reward:{np.sum(rewards):8.2f} loss:{loss:8.2f} mean_rewards:{np.mean(epi_results):8.2f}')\n",
    "    if np.mean(np.mean(epi_results))>200:\n",
    "        break\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Lx2kD2oE3ns5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1710149811927,
     "user": {
      "displayName": "Arindam Dey",
      "userId": "10651625546197419632"
     },
     "user_tz": -330
    },
    "id": "Lx2kD2oE3ns5",
    "outputId": "6e089826-d2af-45cb-80fe-9c369edec1c0"
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "820bd33a-c097-424b-ab0d-bab8745610d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = torch.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1b3e989-976d-44b3-9774-6f41a6b7c871",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122618,
     "status": "ok",
     "timestamp": 1710149806899,
     "user": {
      "displayName": "Arindam Dey",
      "userId": "10651625546197419632"
     },
     "user_tz": -330
    },
    "id": "c1b3e989-976d-44b3-9774-6f41a6b7c871",
    "outputId": "94c3ceff-2bcf-46a0-abd5-c37cac9503fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epi = 0 result 109.03\n",
      "epi = 1 result 200.57\n",
      "epi = 2 result 123.43\n",
      "epi = 3 result 87.41\n",
      "epi = 4 result 136.71\n",
      "epi = 5 result 229.54\n",
      "epi = 6 result 223.78\n",
      "epi = 7 result 223.66\n",
      "epi = 8 result 97.88\n",
      "epi = 9 result 243.42\n"
     ]
    }
   ],
   "source": [
    "eval_env = gym.make(env_id,render_mode=\"human\")\n",
    "\n",
    "for epi in range(10):\n",
    "\n",
    "    s = eval_env.reset()[0]\n",
    "    term = False\n",
    "    trunc = False\n",
    "    score = 0\n",
    "    n=0\n",
    "    while not any([term, trunc]):\n",
    "\n",
    "        obs = torch.FloatTensor(np.expand_dims(s,0)).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p_vals = saved_model(obs)\n",
    "            p_vals = torch.squeeze(p_vals)\n",
    "\n",
    "        p_vals = p_vals.detach().cpu().numpy()\n",
    "        #a = np.random.choice(a_size, p=p_vals)\n",
    "        a = np.argmax(p_vals)\n",
    "        s, r, term ,trunc , _  = eval_env.step(a)\n",
    "        #s = np.copy(s_)\n",
    "        #env.render()\n",
    "        n+=1\n",
    "        score+=r\n",
    "        if score >=200:\n",
    "            break\n",
    "\n",
    "    print(f'{epi = } result {score:4.2f}')\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb03b7e-eb64-4f17-9b77-0e4e457f61f9",
   "metadata": {
    "id": "3cb03b7e-eb64-4f17-9b77-0e4e457f61f9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
